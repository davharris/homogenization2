---
title: "Re-considering the agenda for biotic homogenization research"
author: "David J. Harris"
output: 
  pdf_document:
    fig_caption: true
    keep_tex: true
bibliography: "My Library.bib"
fontsize: 11pt
geometry: margin=1.25in
csl: ecology.csl
header-includes:
  - \usepackage{setspace}
abstract: ""
---

\onehalfspacing

As human influence creates the conditions for some species to spread globally and for others to go extinct, community ecologists have become increasingly concerned about the loss of local biotic distinctiveness, or biotic homogenization. Homogenization is typically quantified as an increase in the average Jaccard similarity among pairs of sites on a landscape ($\bar{J}$, defined more precisely below). Community ecologists have struggled, however, to scale site-level biotic turnover into predictable changes in this quantity. While several frameworks have been proposed for understanding these effects, they are cumbersome to use in practice. For example, @olden_toward_2003's framework involves classifying biotic turnover events into 14 categories, while @rosenblad_new_2016's framework involves six. In either framework, a researcher may need to keep track of thousands of such events across thousands of pairs of sites. Moreover, these pairs of sites are not statistically independent of one another, as each site belongs to many pairs. Worse, many event types are compatible with either homogenization or differentiation, depending on the prior state of the community.  This complexity makes it difficult to test researchers' claims that their framework can explain commonly-observed patterns.

<!--Importantly, they identify a "pivot point" in initial similarity levels that seems to control whether a given set of introductions and extinctions will increase similarity or decrease it (although they do not provide a mechanism behind the existence of this pivot point, how robust it is to different kinds of biotic changes, or how to easily find its value). -->

The Jaccard similarity between site $i$ and $j$ ($\bar{J}$) is defined as the proportion of species that are shared between them. More precisely, it is the number of species that are shared between the two sites ($S_{ij}$) divided by the number of species that occur in at least one ($T_{ij}$). The landscape-level mean Jaccard similarity value that homogenization research has largely focused on is therefore given by

$$\bar{J} = \frac{1}{{{n}\choose{2}}}\sum_{i \neq j} \bigg(\frac{S_{ij}}{T_{ij}}\bigg),$$

where $n$ is the number of sites on the landscape (e.g. islands in an archipelago) and $n\choose2$ is the number of site pairs, equal to $n(n-1)/2$. Most existing frameworks focus on tracking biotic turnover's effects on individual $S_{ij}$ and $T_{ij}$ values [e.g. @olden_toward_2003; @rosenblad_new_2016]. However, there is good reason to believe that this level of detail is not necessary for understanding $\bar{J}$. Using 47 large data sets from the USDA PLANTS database [one for each of the contiguous US states except Delaware; @usda_nrcs_plants_2010], I found that independently shuffling the list of sites occupied by each species typically only affects $\bar{J}$ by a tiny amount (X on a scale from 0 to 1; Appendix 1). 

If similarity and homogenization do not depend strongly on which sites are occupied by which species, then what does matter? In @harris_occupancy_2011, two colleagues and I showed (empirically and with an appeal to the law of large numbers) that average similarity depends primarily on the proportion of sites occupied by each species. Specifically, we defined an approximation to mean Jaccard similarity, $J^*$, given by the average value of $S_{ij}$ divided by the average value of $T_{ij}$. Substituting in formulas for these means, we derived

$$J^*=\sum_k{p_kn \choose 2} \Big/ \sum_k\Bigg[{n\choose 2} - {(1 - p_k)n\choose 2}\Bigg],$$

where $p_k$ is the proportion of sites occupied by species $k$.

Despite the omission of any information at the level of individual sites or site pairs, we showed that the approximation explained 99.8% of the variance in $\bar{J}$ across the 47 USDA PLANTS data sets. It also explained an average of 98.8% of the variance in species-level effects on average similarity. The paper also introduced the *blender* package [@harris_blender:_2014] for R [@r_core_team_r:_2015], which allows users to easily perform these calculations. Similar results were presented around the same time by @chase_using_2011 and by @vergara_island_2011.

In addition to explaining most of the variance, the $J^*$ approximation leads naturally to several other insights.

First, $J^*$ leads to a notion of "effective occupancy", which @harris_occupancy_2011 denoted $p^*$. This (approximate?) weighted average of the the species' $p_k$ values acts as a "center of gravity" for average similarity: species whose $p_k$ values exceed $p^*$ pull its value up, while species with smaller $p_k$ value pull $p^*$ down. As a result, $p*$ acts as a threshold occupancy between net homogenizing and net differentiating effect is a weighted average of the occupancy rates in the community: increasing a species' occupancy rate above a landscape's $p^*$ value will raise the whole community's effective occupancy and cause homogenization, while decreasing a species' occupancy rate below this threshold (or introducing a new rare species) will reduce $p^*$ and cause differentiation.  The existence of such a threshold has been clear to homogenization researchers for a long time [refs], but its location is not well known.

A large portion of the homogenization literature can be explained by this single value. As discussed in @harris_occupancy_2011 (citations omitted):

> $p^*$ also unites many previously disconnected results. For instance, why do older invaders increase similarity more than recent ones)? And why are local range expansions associated with greater homogenization than invasions from other continents? In both cases, the answer can be boiled down to occupancy. Species that have had longer to spread or whose local occupancy rates did not start at zero will have higher occupancy rates and are therefore more likely to contribute to increased similarity.

These explanations are similar to those suggested by @rosenblad_new_2016, but do not require any speculation about individual pairs of sites in other researchers' data sets. 

One point that @harris_occupancy_2011 made but did not emphasize is that the residuals from the $J^*$ approximation are given by an identity from @welsh_fallacy_1988:

$$\bar{J}=J^* + \frac{\textrm{cov}( T_{ij}, S_{ij} \big/T_{ij}) }{ \mathrm{mean}(T_{ij})},$$ 

where $\mathrm{cov}$ refers to the population covariance (rather than the more familiar sample covariance). In other words, $\bar{J}$ can be exactly decomposed into an occupancy component and a covariance component[^1]. In 2011, we largely disregarded the covariance component because it was usually small, but it has important consequences for the way we think about homogenization. In general, it implies that landscapes whose local species compositions are determined by a small number of important factors (which will tend to have negative covariances) will have lower mean similarity values than would be implied by their occupancy rates (Figure 1). The covariance term also implies a possible discrepancy between an intuitive view of beta diversity and the one given by $\bar{J}$ (Figure 1c); this apparent conflict deserves further scrutiny.

[^1]: Note that our 2011 treatment of this decomposition contained a sign error in the second Appendix.

If most of the variance studied in homogenization research can be explained by $p^*$ or $J^*$ and the rest can be explained by a simple covariance term, where does this leave the field? At the end of @harris_occupancy_2011, we listed three paths forward, each of which remains promising five years later.

First, to the extent that $p^*$ explains most of the variance, homogenization researchers should focus on explaining and predicting changes in species' occupancy rates. These are already important for other reasons in basic and applied community ecology.

Second, researchers should increase their focus on the covariance effects that cause deviations from $J^*$ or from permutation-based null distributions [@chase_drought_2007; @chase_drought_2011]. 

Third, the fact that average Jaccard similarity can be calculated with so little ecological information (just occupancy rates and a covariance term) suggests that a great deal of information is lost during the averaging process. To that end, homogenization researchers should continue to think about similarity at scales below the landscape level (e.g. relationships between pairwise similarity and geographic distance). As the focus of homogenization research shifts toward sub-landscape scales, a deeper understanding of biotic turnover on individual pairs of sites [as provided by the frameworks of @olden_toward_2003 and @rosenblad_new_2016] will become increasingly valuable. 



<!--Reducing the distinctiveness of the extreme site types in Figure [X] intuitively seems like a form of homogenization, even though it would decrease mean Jaccard similarity and thus typically be considered differentating.  Ecologists should thus consider whether mean Jaccard similarity is the best metric for their purposes, or whether they would be better served by keeping track of something like the number of low-similarity pairs. More generally, explaining the variance in similarity among pairs of sites within a landscape (as ecologists frequently do by regressing similarity against geographic distance or other factors) will become increasingly important. -->


# References
\singlespacing
